{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y=make_classification(n_samples=2000, n_features=20,n_classes=2,weights=[1,1],random_state=1)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####               Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF train roc-auc: 1.0\n",
      "RF test roc-auc: 0.9836166666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train,y_train)\n",
    "ytrain_pred = rf_model.predict_proba(X_train)\n",
    "print(\"RF train roc-auc: {}\".format(roc_auc_score(y_train,ytrain_pred[:,1])))\n",
    "ytest_pred = rf_model.predict_proba(X_test)\n",
    "print(\"RF test roc-auc: {}\".format(roc_auc_score(y_test,ytest_pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   #### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR train roc-auc: 0.9863568922694498\n",
      "LR test roc-auc: 0.9885777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "ytrain_pred = lr.predict_proba(X_train)\n",
    "print(\"LR train roc-auc: {}\".format(roc_auc_score(y_train,ytrain_pred[:,1])))\n",
    "ytest_pred = lr.predict_proba(X_test)\n",
    "print(\"LR test roc-auc: {}\".format(roc_auc_score(y_test,ytest_pred[:,1])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada_classifier train roc-auc: 0.9975081174960356\n",
      "ada_classifier test roc-auc: 0.9826111111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "ada_classifier = AdaBoostClassifier()\n",
    "ada_classifier.fit(X_train,y_train)\n",
    "ytrain_pred = ada_classifier.predict_proba(X_train)\n",
    "print(\"ada_classifier train roc-auc: {}\".format(roc_auc_score(y_train,ytrain_pred[:,1])))\n",
    "ytest_pred = ada_classifier.predict_proba(X_test)\n",
    "print(\"ada_classifier test roc-auc: {}\".format(roc_auc_score(y_test,ytest_pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn_classifier train roc-auc: 0.981670071491109\n",
      "knn_classifier test roc-auc: 0.9426111111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_classifier.fit(X_train,y_train)\n",
    "ytrain_pred = knn_classifier.predict_proba(X_train)\n",
    "print(\"knn_classifier train roc-auc: {}\".format(roc_auc_score(y_train,ytrain_pred[:,1])))\n",
    "ytest_pred = knn_classifier.predict_proba(X_test)\n",
    "print(\"knn_classifier test roc-auc: {}\".format(roc_auc_score(y_test,ytest_pred[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we focus on selecting the best threshold for maximum accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble test roc-auc: 0.9850333333333333\n"
     ]
    }
   ],
   "source": [
    "pred=[]\n",
    "for model in [rf_model,lr,ada_classifier,knn_classifier]:\n",
    "    pred.append(pd.Series(model.predict_proba(X_test)[:,1]))\n",
    "final_prediction = pd.concat(pred,axis=1).mean(axis=1)\n",
    "print(\"Ensemble test roc-auc: {}\".format(roc_auc_score(y_test,final_prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.991861</td>\n",
       "      <td>0.559186</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.463282</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.966929</td>\n",
       "      <td>0.538202</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.761539</td>\n",
       "      <td>0.509875</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0.779443</td>\n",
       "      <td>0.490344</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.024239</td>\n",
       "      <td>0.461121</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.441377</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.984385</td>\n",
       "      <td>0.532403</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.441720</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>0.99</td>\n",
       "      <td>0.989540</td>\n",
       "      <td>0.559890</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2    3\n",
       "0    0.99  0.991861  0.559186  1.0\n",
       "1    0.01  0.000008  0.463282  0.0\n",
       "2    0.95  0.966929  0.538202  0.8\n",
       "3    0.88  0.761539  0.509875  0.8\n",
       "4    0.52  0.779443  0.490344  0.4\n",
       "..    ...       ...       ...  ...\n",
       "595  0.01  0.024239  0.461121  0.0\n",
       "596  0.04  0.000003  0.441377  0.0\n",
       "597  0.99  0.984385  0.532403  1.0\n",
       "598  0.02  0.001147  0.441720  0.2\n",
       "599  0.99  0.989540  0.559890  0.8\n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(pred,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.885262\n",
       "1      0.118323\n",
       "2      0.813783\n",
       "3      0.737853\n",
       "4      0.547447\n",
       "         ...   \n",
       "595    0.123840\n",
       "596    0.120345\n",
       "597    0.876697\n",
       "598    0.165717\n",
       "599    0.834857\n",
       "Length: 600, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### creating the thresholds and accuracy for all four combined models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.9134413 , 0.9134413 , 0.90873256, 0.90827475, 0.79993823,\n",
       "       0.7980558 , 0.77390513, 0.77321156, 0.76847738, 0.76787124,\n",
       "       0.74723392, 0.74637362, 0.71525211, 0.71393711, 0.65537883,\n",
       "       0.65493537, 0.60656376, 0.58925354, 0.56827749, 0.56486186,\n",
       "       0.54744674, 0.54139283, 0.52865858, 0.50627948, 0.49669266,\n",
       "       0.48366892, 0.4471034 , 0.39405357, 0.38879719, 0.34636723,\n",
       "       0.34336612, 0.23904122, 0.23890421, 0.23457968, 0.23396893,\n",
       "       0.21245158, 0.20598417, 0.12312642, 0.1228351 , 0.10498954])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Combined thresholds for all the four model\n",
    "fpr,tpr,thresholds=roc_curve(y_test,final_prediction)\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thresholds</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.447103</td>\n",
       "      <td>0.961667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.541393</td>\n",
       "      <td>0.961667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.547447</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.483669</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.506279</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.528659</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.496693</td>\n",
       "      <td>0.958333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.564862</td>\n",
       "      <td>0.953333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.394054</td>\n",
       "      <td>0.951667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.568277</td>\n",
       "      <td>0.951667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.388797</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.606564</td>\n",
       "      <td>0.946667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.589254</td>\n",
       "      <td>0.945000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.346367</td>\n",
       "      <td>0.938333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.654935</td>\n",
       "      <td>0.936667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.343366</td>\n",
       "      <td>0.936667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.655379</td>\n",
       "      <td>0.935000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.713937</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.715252</td>\n",
       "      <td>0.915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.239041</td>\n",
       "      <td>0.881667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.238904</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.746374</td>\n",
       "      <td>0.878333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.234580</td>\n",
       "      <td>0.878333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.747234</td>\n",
       "      <td>0.876667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.233969</td>\n",
       "      <td>0.876667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.767871</td>\n",
       "      <td>0.855000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.768477</td>\n",
       "      <td>0.853333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.212452</td>\n",
       "      <td>0.848333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.205984</td>\n",
       "      <td>0.846667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.773212</td>\n",
       "      <td>0.843333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.773905</td>\n",
       "      <td>0.841667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.799938</td>\n",
       "      <td>0.815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.798056</td>\n",
       "      <td>0.815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.123126</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.122835</td>\n",
       "      <td>0.665000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.908275</td>\n",
       "      <td>0.506667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.908733</td>\n",
       "      <td>0.505000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.104990</td>\n",
       "      <td>0.501667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.913441</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.913441</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    thresholds  accuracy\n",
       "26    0.447103  0.961667\n",
       "21    0.541393  0.961667\n",
       "20    0.547447  0.960000\n",
       "25    0.483669  0.960000\n",
       "23    0.506279  0.960000\n",
       "22    0.528659  0.960000\n",
       "24    0.496693  0.958333\n",
       "19    0.564862  0.953333\n",
       "27    0.394054  0.951667\n",
       "18    0.568277  0.951667\n",
       "28    0.388797  0.950000\n",
       "16    0.606564  0.946667\n",
       "17    0.589254  0.945000\n",
       "29    0.346367  0.938333\n",
       "15    0.654935  0.936667\n",
       "30    0.343366  0.936667\n",
       "14    0.655379  0.935000\n",
       "13    0.713937  0.916667\n",
       "12    0.715252  0.915000\n",
       "31    0.239041  0.881667\n",
       "32    0.238904  0.880000\n",
       "11    0.746374  0.878333\n",
       "33    0.234580  0.878333\n",
       "10    0.747234  0.876667\n",
       "34    0.233969  0.876667\n",
       "9     0.767871  0.855000\n",
       "8     0.768477  0.853333\n",
       "35    0.212452  0.848333\n",
       "36    0.205984  0.846667\n",
       "7     0.773212  0.843333\n",
       "6     0.773905  0.841667\n",
       "4     0.799938  0.815000\n",
       "5     0.798056  0.815000\n",
       "37    0.123126  0.666667\n",
       "38    0.122835  0.665000\n",
       "3     0.908275  0.506667\n",
       "2     0.908733  0.505000\n",
       "39    0.104990  0.501667\n",
       "1     0.913441  0.500000\n",
       "0     1.913441  0.500000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_ls = []\n",
    "for thres in thresholds:\n",
    "    y_pred = np.where(final_prediction>thres,1,0)\n",
    "    accuracy_ls.append(accuracy_score(y_test,y_pred, normalize=True))\n",
    "    \n",
    "accuracy_ls = pd.concat([pd.Series(thresholds),pd.Series(accuracy_ls)],axis=1)\n",
    "accuracy_ls.columns = ['thresholds','accuracy']\n",
    "accuracy_ls.sort_values(by='accuracy',ascending=False,inplace=True)\n",
    "accuracy_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting the ROc Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(fpr,tpr, color='b',label='ROC')\n",
    "plt.plot([0,1],[0,1],linestyle='--',color='black')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Result\n",
    "From the experimentation above, it is observed that the threshold of 0.447103 at 96.2% accuracy is the best threshold for our classification."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
